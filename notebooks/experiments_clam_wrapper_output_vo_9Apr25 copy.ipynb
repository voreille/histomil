{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca8a547",
   "metadata": {},
   "source": [
    "# ðŸ“Š Experiment: CLAM wrapper output visualisation and evaluation\n",
    "**Date:** 2025-04-9  \n",
    "**Author:** Valentin Oreiller\n",
    "**Goal:** Test MIL to be used as a filter for tile mining of LUAD tumor tiles\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup & Imports\n",
    "## 2. Data Loading\n",
    "## 3. Preprocessing\n",
    "## 4. Experiments / Model Training\n",
    "## 5. Evaluation\n",
    "## 6. Observations & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee556a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import Trainer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from histomil.data.torch_datasets import HDF5WSIDatasetCLAM, HDF5WSIDatasetCLAMWithTileID\n",
    "from histomil.models.models import load_model, get_device\n",
    "from histomil.models.clam_wrapper import PL_CLAM_SB\n",
    "from histomil.visualization.heatmap import compute_attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_dir = Path(\"/mnt/nas6/data/CPTAC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wsi_path(wsi_id, wsi_dir):\n",
    "    wsi_paths = [f for f in wsi_dir.rglob(wsi_id + \".svs\")]\n",
    "    if len(wsi_paths) > 1:\n",
    "        raise ValueError(f\"Multiple WSI files found for {wsi_id}: {wsi_paths}\")\n",
    "    return wsi_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d73529",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = \"/home/valentin/workspaces/histomil/data/processed/embeddings/superpixels_moco_org.h5\"\n",
    "\n",
    "val_dataset = HDF5WSIDatasetCLAMWithTileID(hdf5_path, split=\"test\")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=12,\n",
    "    collate_fn=HDF5WSIDatasetCLAMWithTileID.get_collate_fn_ragged(),\n",
    ")\n",
    "test_dataset = HDF5WSIDatasetCLAM(hdf5_path, split=\"test\")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=12,\n",
    "    collate_fn=HDF5WSIDatasetCLAM.get_collate_fn_ragged(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mil_weights = \"/home/valentin/workspaces/histomil/models/mil/UNI2_mil_v1.ckpt\"\n",
    "mil_weights = \"/home/valentin/workspaces/histomil/models/mil/test/clam/epoch=89-step=148860.ckpt\"\n",
    "device = get_device(gpu_id=1)\n",
    "# mil_aggregator = AttentionAggregatorPL.load_from_checkpoint(mil_weights)\n",
    "mil_aggregator = PL_CLAM_SB.load_from_checkpoint(mil_weights, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "mil_aggregator.to(device)\n",
    "mil_aggregator.eval()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70748695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_map(attention_map, thumbnail):\n",
    "    # Normalize the attention map between 0 and 1\n",
    "    attention_norm = (attention_map - attention_map.min()) / (\n",
    "        attention_map.max() - attention_map.min()\n",
    "    )\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Show WSI thumbnail\n",
    "    plt.imshow(thumbnail, cmap=\"gray\" if thumbnail.ndim == 2 else None)\n",
    "\n",
    "    # Overlay attention heatmap with transparency\n",
    "    plt.imshow(attention_norm, cmap=\"jet\", alpha=0.5)  # alpha adjusts transparency\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"WSI Thumbnail with Attention Overlay\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf272ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_percentiles(scores):\n",
    "    from scipy.stats import rankdata\n",
    "    scores = rankdata(scores, 'average')/len(scores) * 100   \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f37562",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader_list = list(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ea645",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, labels, tile_ids = val_loader_list[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "print(f\"Batch {batch_idx} with labels {labels[batch_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62556c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = mil_aggregator(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56208c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_scores = F.softmax(output[3], dim=1).cpu().numpy()\n",
    "attention_scores = to_percentiles(output[3].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ebc704",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_id = tile_ids[0].decode(\"utf-8\").split(\"__\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cbb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_path = get_wsi_path(wsi_id, wsi_dir)\n",
    "attention_map, thumbnail = compute_attention_map(\n",
    "    attention_scores,\n",
    "    tile_ids,\n",
    "    tile_size=224,\n",
    "    tile_mpp=1.0,\n",
    "    wsi_path=wsi_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db99110",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_map(attention_map, np.array(thumbnail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22009038",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(devices=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(mil_aggregator, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bcfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.validate(mil_aggregator, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607119e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
