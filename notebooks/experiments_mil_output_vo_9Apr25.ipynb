{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca8a547",
   "metadata": {},
   "source": [
    "# ðŸ“Š Experiment: MIL output visualisation and evaluation\n",
    "**Date:** 2025-04-9  \n",
    "**Author:** Valentin Oreiller\n",
    "**Goal:** Test MIL to be used as a filter for tile mining of LUAD tumor tiles\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup & Imports\n",
    "## 2. Data Loading\n",
    "## 3. Preprocessing\n",
    "## 4. Experiments / Model Training\n",
    "## 5. Evaluation\n",
    "## 6. Observations & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee556a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from histomil.data.torch_datasets import HDF5WSIDatasetWithTileID, HDF5WSIDataset\n",
    "from histomil.models.models import load_model, get_device\n",
    "from histomil.models.mil_models import AttentionAggregatorPL\n",
    "from histomil.visualization.heatmap import compute_attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_dir = Path(\"/mnt/nas6/data/CPTAC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wsi_path(wsi_id, wsi_dir):\n",
    "    wsi_paths = [f for f in wsi_dir.rglob(wsi_id + \".svs\")]\n",
    "    if len(wsi_paths) > 1:\n",
    "        raise ValueError(f\"Multiple WSI files found for {wsi_id}: {wsi_paths}\")\n",
    "    return wsi_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d73529",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = \"/home/valentin/workspaces/histomil/data/processed/embeddings/superpixels_resnet50__alpha_0.5__ablation.h5\"\n",
    "\n",
    "val_dataset = HDF5WSIDatasetWithTileID(hdf5_path, split=\"test\")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=12,\n",
    "    collate_fn=HDF5WSIDatasetWithTileID.get_collate_fn_ragged(),\n",
    ")\n",
    "test_dataset = HDF5WSIDataset(hdf5_path, split=\"test\")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=12,\n",
    "    collate_fn=HDF5WSIDataset.get_collate_fn_ragged(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_weights = \"/mnt/nas7/data/Personal/Darya/saved_models/superpixels_resnet50__alpha_0.5__ablation_99.pth\"\n",
    "mil_weights = \"/home/valentin/workspaces/histomil/models/mil/superpixels_org_alpha0.5_tutobene.ckpt\"\n",
    "device = get_device(gpu_id=0)\n",
    "mil_aggregator = AttentionAggregatorPL.load_from_checkpoint(mil_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ea645",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_ids, embeddings, labels, tile_ids = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "mil_aggregator.to(device)\n",
    "mil_aggregator.eval()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70748695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_map(attention_map, thumbnail):\n",
    "    # Normalize the attention map between 0 and 1\n",
    "    attention_norm = (attention_map - attention_map.min()) / (\n",
    "        attention_map.max() - attention_map.min()\n",
    "    )\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Show WSI thumbnail\n",
    "    plt.imshow(thumbnail, cmap=\"gray\" if thumbnail.ndim == 2 else None)\n",
    "\n",
    "    # Overlay attention heatmap with transparency\n",
    "    plt.imshow(attention_norm, cmap=\"jet\", alpha=0.5)  # alpha adjusts transparency\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"WSI Thumbnail with Attention Overlay\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 5\n",
    "print(f\"Batch {batch_idx} with labels {labels[batch_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embeddings[batch_idx].to(device)\n",
    "pred, proba, attention_scores = mil_aggregator.predict_one_embedding(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56208c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f549c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores = attention_scores.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cbb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_id = wsi_ids[batch_idx]\n",
    "wsi_path = get_wsi_path(wsi_id, wsi_dir)\n",
    "attention_map, thumbnail = compute_attention_map(\n",
    "    attention_scores,\n",
    "    tile_ids[batch_idx],\n",
    "    tile_size=224,\n",
    "    tile_mpp=1.0,\n",
    "    wsi_path=wsi_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db99110",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_map(attention_map, np.array(thumbnail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22009038",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(mil_aggregator, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bcfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607119e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
